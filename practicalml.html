<!DOCTYPE html>
<html>
<head>
  <title>Practical ML</title>
  <meta charset="utf-8">
</head>

<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.</p>
<p>In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise.</p>
</div>
<div id="data-preprocessing" class="section level2">
<h2>Data Preprocessing</h2>
<pre class="r"><code>library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)</code></pre>
<div id="download-the-data" class="section level3">
<h3>Download the Data</h3>
<pre class="r"><code>trainUrl &lt;-&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;
testUrl &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;
trainFile &lt;- &quot;./data/pml-training.csv&quot;
testFile  &lt;- &quot;./data/pml-testing.csv&quot;
if (!file.exists(&quot;./data&quot;)) {
  dir.create(&quot;./data&quot;)
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method=&quot;curl&quot;)
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method=&quot;curl&quot;)
}</code></pre>
</div>
<div id="read-the-data" class="section level3">
<h3>Read the Data</h3>
<p>After downloading the data from the data source, we can read the two csv files into two data frames.</p>
<pre class="r"><code>trainRaw &lt;- read.csv(&quot;./data/pml-training.csv&quot;)
testRaw &lt;- read.csv(&quot;./data/pml-testing.csv&quot;)
dim(trainRaw)</code></pre>
<pre><code>## [1] 19622   160</code></pre>
<pre class="r"><code>dim(testRaw)</code></pre>
<pre><code>## [1]  20 160</code></pre>
<p>The training data set contains 19622 observations and 160 variables, while the testing data set contains 20 observations and 160 variables. The “classe” variable in the training set is the outcome to predict.</p>
</div>
<div id="clean-the-data" class="section level3">
<h3>Clean the data</h3>
<p>In this step, we will clean the data and get rid of observations with missing values as well as some meaningless variables.</p>
<pre class="r"><code>sum(complete.cases(trainRaw))</code></pre>
<pre><code>## [1] 406</code></pre>
<p>First, we remove columns that contain NA missing values.</p>
<pre class="r"><code>trainRaw &lt;- trainRaw[, colSums(is.na(trainRaw)) == 0] 
testRaw &lt;- testRaw[, colSums(is.na(testRaw)) == 0] </code></pre>
<p>Next, we get rid of some columns that do not contribute much to the accelerometer measurements.</p>
<pre class="r"><code>classe &lt;- trainRaw$classe
trainRemove &lt;- grepl(&quot;^X|timestamp|window&quot;, names(trainRaw))
trainRaw &lt;- trainRaw[, !trainRemove]
trainCleaned &lt;- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe &lt;- classe
testRemove &lt;- grepl(&quot;^X|timestamp|window&quot;, names(testRaw))
testRaw &lt;- testRaw[, !testRemove]
testCleaned &lt;- testRaw[, sapply(testRaw, is.numeric)]</code></pre>
<p>Now, the cleaned training data set contains 19622 observations and 53 variables, while the testing data set contains 20 observations and 53 variables. The “classe” variable is still in the cleaned training set.</p>
</div>  

## yaw_belt           3   1
## total_accel_belt   4   1
## accel_belt_y       9   1
## accel_belt_z      10   1
## accel_belt_x       8   2
## magnet_belt_x     11   2
## roll_belt          1   3
## roll_belt          1   4
## accel_belt_y       9   4
## accel_belt_z      10   4
## pitch_belt         2   8
## magnet_belt_x     11   8
## roll_belt          1   9
## total_accel_belt   4   9
## accel_belt_z      10   9
## roll_belt          1  10
## total_accel_belt   4  10
## accel_belt_y       9  10
## pitch_belt         2  11
## accel_belt_x       8  11
## gyros_arm_y       19  18
## gyros_arm_x       18  19
## magnet_arm_x      24  21
## accel_arm_x       21  24
## magnet_arm_z      26  25
## magnet_arm_y      25  26
## accel_dumbbell_x  34  28
## accel_dumbbell_z  36  29
## gyros_dumbbell_z  33  31
## gyros_forearm_z   46  31
## gyros_dumbbell_x  31  33
## gyros_forearm_z   46  33
## pitch_dumbbell    28  34
## yaw_dumbbell      29  36
## gyros_forearm_z   46  45
## gyros_dumbbell_x  31  46
## gyros_dumbbell_z  33  46
## gyros_forearm_y   45  46</code></pre>
<p>It’s noticed there are some variables correlated, one way to handle
them and simplify the fitting of the model is to use PCA pre-processing
to reduce the number of variables.</p>
</div>
<div id="cross-validation" class="section level1">
<h1>Cross validation</h1>
<p>The strategy to find a predicting model is to try 3 different
methods, having in mind that the output variables is a multi-factor with
5 levels which means our method should be as the classification type.
For this exercise the options for method will be:</p>
<ol style="list-style-type: lower-alpha">
<li>Random Forest, is both Classification and Regression method</li>
<li>Generalized Linear Model, is both Classification and Regression
method using multinomial type.</li>
<li>Bagged, also a Classification. adn Regression method</li>
</ol>
<p>In order to select the best option for a method, the predictor
dataset will be split into Training and Validation, the split will be
done by picking a defined percentage of random data per level of the
classe variable, this can be done by using the createDatapartition
function and set classe as input:</p>
<pre class="r"><code>set.seed(123)
inTrain &lt;- createDataPartition(predictors$classe, p=0.7, list=FALSE)

training &lt;- predictors[inTrain,]
validation &lt;- predictors[-inTrain,]</code></pre>
</div>
<div id="pre-processing" class="section level1">
<h1>Pre-processing</h1>
<p>As mentioned before, since there are some predictors that probed to
be colinear a PCA pre-processing method is going to be use to simplify
the analysis. The function train have this option.</p>
</div>
<div id="fitting-a-model" class="section level1">
<h1>Fitting a model</h1>
<ol style="list-style-type: decimal">
<li>The first option to be use is the random forest method, there is no
need for further transformation or manipulation of the data:</li>
</ol>
<pre class="r"><code>model_rf &lt;- train(classe ~ ., data = training, preProcess=&quot;pca&quot;,
               method = &#39;rf&#39;, tuneLength = 1)</code></pre>
<p>Now we will get the confusion matrix to revew the results of the
model in the validation dataset:</p>
<pre class="r"><code>confusionMatrix(validation$classe,predict(model_rf,validation))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1662    1    8    2    1
##          B   17 1103   18    0    1
##          C    4   15 1001    4    2
##          D    0    0   42  918    4
##          E    3    5   12    2 1060
## 
## Overall Statistics
##                                           
##                Accuracy : 0.976           
##                  95% CI : (0.9718, 0.9798)
##     No Information Rate : 0.2865          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9697          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9858   0.9813   0.9260   0.9914   0.9925
## Specificity            0.9971   0.9924   0.9948   0.9907   0.9954
## Pos Pred Value         0.9928   0.9684   0.9756   0.9523   0.9797
## Neg Pred Value         0.9943   0.9956   0.9835   0.9984   0.9983
## Prevalence             0.2865   0.1910   0.1837   0.1573   0.1815
## Detection Rate         0.2824   0.1874   0.1701   0.1560   0.1801
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9915   0.9869   0.9604   0.9910   0.9940</code></pre>
<p>The model is quite accurate in 97.6% , class C is where most of the
misses occur and a p-value of 2.2e-16.</p>
<ol start="2" style="list-style-type: decimal">
<li>Next is to fit a model using Generalized Linear Model with the train
function:</li>
</ol>
<pre class="r"><code>model_glm &lt;- train(classe ~ ., data = training,
                 preProcess=c(&quot;pca&quot;,&quot;center&quot;,&quot;scale&quot;),
                 method = &#39;glmnet&#39;,family=&quot;multinomial&quot;,
                 type.multinomial=&quot;grouped&quot;)</code></pre>
<p>Let’s review the confusion matrix:</p>
<pre class="r"><code>confusionMatrix(validation$classe,predict(model_glm,validation))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1106  139  170  216   43
##          B  268  494  174   89  114
##          C  304  112  481   99   30
##          D   94  127  104  534  105
##          E  108  192  129  137  516
## 
## Overall Statistics
##                                           
##                Accuracy : 0.532           
##                  95% CI : (0.5192, 0.5448)
##     No Information Rate : 0.3195          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.4059          
##                                           
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.5883  0.46429  0.45463  0.49674  0.63861
## Specificity            0.8582  0.86621  0.88709  0.91060  0.88852
## Pos Pred Value         0.6607  0.43371  0.46881  0.55394  0.47689
## Neg Pred Value         0.8162  0.87990  0.88125  0.89006  0.93920
## Prevalence             0.3195  0.18080  0.17978  0.18267  0.13730
## Detection Rate         0.1879  0.08394  0.08173  0.09074  0.08768
## Detection Prevalence   0.2845  0.19354  0.17434  0.16381  0.18386
## Balanced Accuracy      0.7232  0.66525  0.67086  0.70367  0.76357</code></pre>
<p>GLM fits a model with a 53.2% accuracy, classification error is
distributed in all classes.</p>
<ol start="3" style="list-style-type: decimal">
<li>Last is a model fit with bagging method:</li>
</ol>
<pre class="r"><code>model_bag &lt;- train(classe ~ ., data = training, preProcess=&quot;pca&quot;,
                  method = &#39;treebag&#39;, mfinal =25,
                  tuneLength = 1)</code></pre>
<p>And the confusion matrix will show:</p>
<pre class="r"><code>confusionMatrix(validation$classe,predict(model_bag,validation))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1642    7   11    9    5
##          B   27 1066   31    6    9
##          C    4   15  995    8    4
##          D    1    2   37  917    7
##          E    8   11   13    6 1044
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9624          
##                  95% CI : (0.9573, 0.9672)
##     No Information Rate : 0.2858          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9525          
##                                           
##  Mcnemar&#39;s Test P-Value : 6.223e-08       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9762   0.9682   0.9154   0.9693   0.9766
## Specificity            0.9924   0.9847   0.9935   0.9905   0.9921
## Pos Pred Value         0.9809   0.9359   0.9698   0.9512   0.9649
## Neg Pred Value         0.9905   0.9926   0.9811   0.9941   0.9948
## Prevalence             0.2858   0.1871   0.1847   0.1607   0.1816
## Detection Rate         0.2790   0.1811   0.1691   0.1558   0.1774
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9843   0.9765   0.9545   0.9799   0.9844</code></pre>
<p>Bagging model achieves a 96.2 % accuracy.</p>
<p>Random Forest model seems to have a better results on predicting the
validation dataset than the other 2 models (glm,bag), the out of sample
error is expected to be a 0.034% vs 0.038% for the bagging model, hence,
we will use random forest to make the prediction on the test
dataset.</p>
</div>
<div id="prediction-on-testing-dataset" class="section level1">
<h1>Prediction on Testing dataset</h1>
<p>Using the random forest model, let’s predict the classe on each of
the observations in the testing dataset, then add the results to the
testing data frame:</p>
<p>Below is the results of the prediction:</p>
<pre><code>## # A tibble: 20 × 2
##    problem_id classe
##         &lt;dbl&gt; &lt;fct&gt; 
##  1          1 B     
##  2          2 C     
##  3          3 D     
##  4          4 E     
##  5          5 A     
##  6          6 E     
##  7          7 D     
##  8          8 B     
##  9          9 A     
## 10         10 A     
## 11         11 E    
## 12         12 C     
## 13         13 B     
## 14         14 A     
## 15         15 E     
## 16         16 E     
## 17         17 A     
## 18         18 B     
## 19         19 B     
## 20         20 B</code></pre>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
 
</body>
</html>
